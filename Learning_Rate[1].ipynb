{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/DeepLearning/blob/main/Learning_Rate%5B1%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z2kILHRWcKg"
      },
      "source": [
        "# Transfer learning - Learning Rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggcpfBwQcU8"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3w2sce8WXYa"
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDchYyEo5Fe"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYMYVmxMpX2z"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEw9S-Up23y"
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=True, download=True,transform=transform)\n",
        "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=False, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1CRA2mdqZ8R"
      },
      "source": [
        "for images, labels in trainloader:\n",
        "  print(images.size(), labels.size())\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBchPi4jvHMj"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avx6J-_Mvfy3"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7URaKbIwhse"
      },
      "source": [
        "for i in range(0,7):\n",
        "  model.classifier[i].requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBWZLtJwt3P"
      },
      "source": [
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(4096,512),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.5),\n",
        "                      nn.Linear(512,10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                      )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXPMdB3b-9g"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IGZ_qw9NA8u"
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9-eEGnxW77"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = model.to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vamBkzek_ZfR"
      },
      "source": [
        "## Training from the Fully Connected Network onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3WWNZkQ_ZfS"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeEZA-WO9joV"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ-xpFU-_ZfU"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "\n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "\n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6j6rXQe_ZfW"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPEeLaHK_ZfW"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "\n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "\n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "\n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLAXsh1S5XB9"
      },
      "source": [
        "## Un-freezing & training on the LAST CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7nvP9B9R8b"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaUeud5I7Tez"
      },
      "source": [
        "for i in range(24,31):\n",
        "  model.features[i].requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3H1alJg-keE"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.features[24].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[26].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[28].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_-YlZp5XB-"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 3\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "\n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "\n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2dNQIjt9JQo"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ichHhboE9JQp"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "\n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "\n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "\n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbOYwAC9rVq"
      },
      "source": [
        "## Un-freezing & training on the LAST TWO CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTUgZSz9rVt"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkn85do59rVw"
      },
      "source": [
        "for i in range(17,24):\n",
        "  model.features[i].requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxRZ0rJ5_SaB"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.features[17].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[19].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[21].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[24].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[26].parameters(), 'lr': lr},\n",
        "    { 'params': model.features[28].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrzemsJ9rV1"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 3\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "\n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "\n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_RCnNg9rV7"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoeCTt29rV8"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "\n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "\n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "\n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}